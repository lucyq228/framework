{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLflow Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, math, tempfile\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Iterator, Tuple, Any\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.linear_model import LinearRegression, Ridge, ElasticNet\n",
    "\n",
    "import mlflow\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# import mlflow\n",
    "\n",
    "TRACK_DIR = os.path.abspath(\"./mlruns_rga_test\")\n",
    "mlflow.set_tracking_uri(f\"file:///{TRACK_DIR.replace(os.sep, '/')}\") # for local testing. not needed for Databricks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def make_tiny_df():\n",
    "    weeks = pd.date_range(\"2023-01-01\", \"2025-06-30\", freq=\"W-SUN\")\n",
    "    n = len(weeks)\n",
    "\n",
    "    rng = np.random.default_rng(42)\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"week_start\": weeks,\n",
    "        # target\n",
    "        \"log_GC\": rng.normal(0, 1, n),\n",
    "    })\n",
    "\n",
    "    # promo + media features\n",
    "    for c in ['digital_promo_1','digital_promo_2','digital_promo_3','digital_promo_4','digital_promo_5',\n",
    "              'media_1','media_2','media_3','media_4','media_5']:\n",
    "        df[c] = rng.normal(0, 1, n)\n",
    "\n",
    "    return df\n",
    "\n",
    "df = make_tiny_df()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Configuration objects (easy to extend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class TimeSplit:\n",
    "    time_split_id: str\n",
    "    train_start: str\n",
    "    train_end: str\n",
    "    test_start: str\n",
    "    test_end: str\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class RunConfig:\n",
    "    # \"fixed\" knobs you said exist\n",
    "    target_node: str              # \"GC\" or \"AC\"\n",
    "    panel_control: str            # \"FE\" / \"Mundlak\" / \"Bayesian\" (placeholder for now)\n",
    "    algorithm: str                # \"OLS\" / \"Ridge\" / \"ElasticNet\"\n",
    "    alpha: float = 0.0\n",
    "    l1_ratio: float = 0.0\n",
    "\n",
    "    # experiment dimensions\n",
    "    feature_block_set_id: str = \"\"\n",
    "    features: Tuple[str, ...] = tuple()\n",
    "    time_split: TimeSplit = None\n",
    "    seed: int = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) MLflow setup (experiment + common tags)\n",
    "\n",
    "Databricks tip: use a workspace path like \"/Users/<you>/RGA/Regressions\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def setup_mlflow(experiment_name: str, common_tags: Dict[str, str]) -> None:\n",
    "#     mlflow.set_experiment(experiment_name)\n",
    "#     mlflow.set_tags(common_tags)\n",
    "\n",
    "def setup_mlflow(experiment_name: str) -> None:\n",
    "    mlflow.set_experiment(experiment_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Search strategy component (swap later)\n",
    "\n",
    "This yields a stream of RunConfig objects. Keep it dumb/simple now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_feature_sets(feature_blocks: Dict[str, List[str]]) -> Dict[str, Tuple[str, ...]]:\n",
    "    \"\"\"\n",
    "    Example: feature_blocks = {\"promo\":[...], \"media\":[...], \"ops\":[...]}\n",
    "    Return a dict of feature_block_set_id -> tuple(features)\n",
    "    \"\"\"\n",
    "    # Minimal example: each single block + all blocks\n",
    "    out = {}\n",
    "    for block, feats in feature_blocks.items():\n",
    "        out[f\"block__{block}\"] = tuple(feats)\n",
    "    all_feats = tuple(sorted({f for feats in feature_blocks.values() for f in feats}))\n",
    "    out[\"block__ALL\"] = all_feats\n",
    "    return out\n",
    "\n",
    "def search_space(\n",
    "    target_node: str,\n",
    "    panel_controls: List[str],\n",
    "    algorithms: List[Dict[str, Any]],\n",
    "    time_splits: List[TimeSplit],\n",
    "    feature_sets: Dict[str, Tuple[str, ...]],\n",
    "    seed: int = 42,\n",
    ") -> Iterator[RunConfig]:\n",
    "    for pc in panel_controls:\n",
    "        for algo in algorithms:\n",
    "            for ts in time_splits:\n",
    "                for fs_id, feats in feature_sets.items():\n",
    "                    yield RunConfig(\n",
    "                        target_node=target_node,\n",
    "                        panel_control=pc,\n",
    "                        algorithm=algo[\"name\"],\n",
    "                        alpha=float(algo.get(\"alpha\", 0.0)),\n",
    "                        l1_ratio=float(algo.get(\"l1_ratio\", 0.0)),\n",
    "                        feature_block_set_id=fs_id,\n",
    "                        features=feats,\n",
    "                        time_split=ts,\n",
    "                        seed=seed,\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Model factory component (swap later)\n",
    "\n",
    "This is where FE/Mundlak/Bayesian wrappers will go. For now it’s vanilla sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(cfg: RunConfig):\n",
    "    if cfg.algorithm == \"OLS\":\n",
    "        return LinearRegression()\n",
    "    if cfg.algorithm == \"Ridge\":\n",
    "        return Ridge(alpha=cfg.alpha, random_state=cfg.seed)\n",
    "    if cfg.algorithm == \"ElasticNet\":\n",
    "        return ElasticNet(alpha=cfg.alpha, l1_ratio=cfg.l1_ratio, random_state=cfg.seed, max_iter=10000)\n",
    "    raise ValueError(f\"Unknown algorithm: {cfg.algorithm}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_get_coef_table(cfg: RunConfig, X_train: pd.DataFrame, y_train: pd.Series):\n",
    "    \"\"\"\n",
    "    Returns: model_object, coef_df\n",
    "    coef_df columns: feature, coef, sign, abs_coef, rank_abscoef, t_stat, p_value\n",
    "    \"\"\"\n",
    "    feats = list(X_train.columns)\n",
    "\n",
    "    if cfg.algorithm == \"OLS\":\n",
    "        # statsmodels gives p-values\n",
    "        X_sm = sm.add_constant(X_train, has_constant=\"add\")\n",
    "        model = sm.OLS(y_train, X_sm).fit()\n",
    "\n",
    "        coef = model.params.drop(\"const\", errors=\"ignore\")\n",
    "        tstat = model.tvalues.drop(\"const\", errors=\"ignore\")\n",
    "        pval = model.pvalues.drop(\"const\", errors=\"ignore\")\n",
    "\n",
    "        df = pd.DataFrame({\n",
    "            \"feature\": coef.index,\n",
    "            \"coef\": coef.values,\n",
    "            \"t_stat\": tstat.reindex(coef.index).values,\n",
    "            \"p_value\": pval.reindex(coef.index).values,\n",
    "        })\n",
    "\n",
    "    else:\n",
    "        # sklearn (no p-values)\n",
    "        model = make_model(cfg)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        coefs = np.asarray(model.coef_).ravel()\n",
    "        df = pd.DataFrame({\n",
    "            \"feature\": feats,\n",
    "            \"coef\": coefs,\n",
    "            \"t_stat\": np.nan,\n",
    "            \"p_value\": np.nan,\n",
    "        })\n",
    "\n",
    "    df[\"abs_coef\"] = df[\"coef\"].abs()\n",
    "    df[\"sign\"] = np.sign(df[\"coef\"]).astype(int)\n",
    "    df = df.sort_values(\"abs_coef\", ascending=False).reset_index(drop=True)\n",
    "    df[\"rank_abscoef\"] = np.arange(1, len(df) + 1)\n",
    "\n",
    "    # simple significance flag (customize threshold later)\n",
    "    df[\"is_significant_05\"] = (df[\"p_value\"] < 0.05)\n",
    "\n",
    "    return model, df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Data prep component (you will replace pieces later)\n",
    "\n",
    "Assumes:\n",
    "\n",
    "df_pd includes store_id, week_start, plus feature columns\n",
    "\n",
    "target columns exist, e.g. log_GC, log_AC (or you can compute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_by_time(df: pd.DataFrame, ts: TimeSplit) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    df = df.copy()\n",
    "    df[\"week_start\"] = pd.to_datetime(df[\"week_start\"])\n",
    "    train = df[(df[\"week_start\"] >= ts.train_start) & (df[\"week_start\"] <= ts.train_end)]\n",
    "    test  = df[(df[\"week_start\"] >= ts.test_start)  & (df[\"week_start\"] <= ts.test_end)]\n",
    "    return train, test\n",
    "\n",
    "def get_target_col(target_node: str) -> str:\n",
    "    # you can change this mapping anytime\n",
    "    if target_node == \"GC\":\n",
    "        return \"log_GC\"\n",
    "    if target_node == \"AC\":\n",
    "        return \"log_AC\"\n",
    "    raise ValueError(\"target_node must be 'GC' or 'AC'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) Logging policy component (what to log)\n",
    "\n",
    "Keep parameters as params; use tags for “indexing / grouping” fields you’ll filter on later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_run_inputs(cfg: RunConfig) -> None:\n",
    "    # Params (queryable, shown in UI)\n",
    "    mlflow.log_params({\n",
    "        \"target_node\": cfg.target_node,\n",
    "        \"panel_control\": cfg.panel_control,\n",
    "        \"algorithm\": cfg.algorithm,\n",
    "        \"alpha\": cfg.alpha,\n",
    "        \"l1_ratio\": cfg.l1_ratio,\n",
    "        \"feature_block_set_id\": cfg.feature_block_set_id,\n",
    "        \"n_features\": len(cfg.features),\n",
    "        \"time_split_id\": cfg.time_split.time_split_id,\n",
    "        \"train_start\": cfg.time_split.train_start,\n",
    "        \"train_end\": cfg.time_split.train_end,\n",
    "        \"test_start\": cfg.time_split.test_start,\n",
    "        \"test_end\": cfg.time_split.test_end,\n",
    "        \"seed\": cfg.seed,\n",
    "    })\n",
    "\n",
    "def log_metrics(prefix: str, y_true, y_pred) -> None:\n",
    "    rmse = math.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    mlflow.log_metrics({\n",
    "        f\"{prefix}_rmse\": rmse,\n",
    "        f\"{prefix}_mae\": mae,\n",
    "        f\"{prefix}_r2\": r2,\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) Fit + log artifacts (coeff table, rank table, config snapshot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coef_table(model, feature_names: List[str]) -> pd.DataFrame:\n",
    "    # Works for linear models that have coef_\n",
    "    coefs = np.asarray(model.coef_).ravel()\n",
    "    df = pd.DataFrame({\"feature\": feature_names, \"coef\": coefs})\n",
    "    df[\"abs_coef\"] = df[\"coef\"].abs()\n",
    "    df[\"sign\"] = np.sign(df[\"coef\"]).astype(int)\n",
    "    df = df.sort_values(\"abs_coef\", ascending=False).reset_index(drop=True)\n",
    "    df[\"rank_abscoef\"] = np.arange(1, len(df) + 1)\n",
    "    return df\n",
    "\n",
    "def log_dataframe_as_csv(df: pd.DataFrame, artifact_path: str, filename: str) -> None:\n",
    "    with tempfile.TemporaryDirectory() as tmpdir:\n",
    "        fpath = os.path.join(tmpdir, filename)\n",
    "        df.to_csv(fpath, index=False)\n",
    "        mlflow.log_artifact(fpath, artifact_path=artifact_path)\n",
    "\n",
    "def log_config_snapshot(cfg: RunConfig) -> None:\n",
    "    payload = {\n",
    "        \"target_node\": cfg.target_node,\n",
    "        \"panel_control\": cfg.panel_control,\n",
    "        \"algorithm\": cfg.algorithm,\n",
    "        \"alpha\": cfg.alpha,\n",
    "        \"l1_ratio\": cfg.l1_ratio,\n",
    "        \"feature_block_set_id\": cfg.feature_block_set_id,\n",
    "        \"features\": list(cfg.features),\n",
    "        \"time_split\": cfg.time_split.__dict__,\n",
    "        \"seed\": cfg.seed,\n",
    "    }\n",
    "    mlflow.log_dict(payload, artifact_file=\"run_config.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8) Single run execution (with failure handling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def run_one_experiment(df_pd: pd.DataFrame, cfg: RunConfig) -> None:\n",
    "#     run_name = f\"{cfg.target_node}__{cfg.panel_control}__{cfg.algorithm}__{cfg.feature_block_set_id}__{cfg.time_split.time_split_id}\"\n",
    "\n",
    "#     with mlflow.start_run(run_name=run_name, nested=True):\n",
    "#         try:\n",
    "#             log_run_inputs(cfg)\n",
    "#             log_config_snapshot(cfg)\n",
    "\n",
    "#             # Data slicing\n",
    "#             train_df, test_df = slice_by_time(df_pd, cfg.time_split)\n",
    "#             ycol = get_target_col(cfg.target_node)\n",
    "\n",
    "#             X_train = train_df.loc[:, list(cfg.features)]\n",
    "#             y_train = train_df[ycol]\n",
    "#             X_test  = test_df.loc[:, list(cfg.features)]\n",
    "#             y_test  = test_df[ycol]\n",
    "\n",
    "#             # Fit\n",
    "#             model = make_model(cfg)\n",
    "#             model.fit(X_train, y_train)\n",
    "\n",
    "#             # Predict + metrics\n",
    "#             pred_train = model.predict(X_train)\n",
    "#             pred_test  = model.predict(X_test)\n",
    "#             log_metrics(\"train\", y_train, pred_train)\n",
    "#             log_metrics(\"test\", y_test, pred_test)\n",
    "\n",
    "#             # Artifacts: coefficients + ranks\n",
    "#             cdf = coef_table(model, list(cfg.features))\n",
    "#             log_dataframe_as_csv(cdf, artifact_path=\"artifacts\", filename=\"coefficients.csv\")\n",
    "\n",
    "#             # Optional: log model (safe to keep optional if volume is huge)\n",
    "#             # mlflow.sklearn.log_model(model, artifact_path=\"model\")\n",
    "\n",
    "#         except Exception as e:\n",
    "#             mlflow.set_tag(\"run_status\", \"failed\")\n",
    "#             mlflow.log_text(str(e), \"error.txt\")\n",
    "#             raise\n",
    "#         else:\n",
    "#             mlflow.set_tag(\"run_status\", \"ok\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active run before: <ActiveRun: >\n",
      "Active run entering child: <ActiveRun: >\n"
     ]
    }
   ],
   "source": [
    "# print(\"Active run before:\", mlflow.active_run())\n",
    "# print(\"Active run entering child:\", mlflow.active_run())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_one_experiment(df_pd: pd.DataFrame, cfg: RunConfig) -> None:\n",
    "    \"\"\"\n",
    "    Execute ONE fully-specified trial and log everything needed for later stability aggregation.\n",
    "\n",
    "    Logs (per run):\n",
    "      - params: target_node, panel_control, algorithm, hyperparams, feature_set_id, n_features, time split, etc.\n",
    "      - metrics: train/test r2/rmse/mae\n",
    "      - artifacts: coefficients.csv (coef/sign/rank + p-values for OLS), run_config.json\n",
    "      - tags: run_status\n",
    "    \"\"\"\n",
    "    run_name = (\n",
    "        f\"{cfg.target_node}__{cfg.panel_control}__{cfg.algorithm}\"\n",
    "        f\"__{cfg.feature_block_set_id}__{cfg.time_split.time_split_id}\"\n",
    "    )\n",
    "\n",
    "    with mlflow.start_run(run_name=run_name, nested=True):\n",
    "        mlflow.set_tag(\"run_type\", \"trial\")\n",
    "        try:\n",
    "            # --- 1) Log inputs (params + config snapshot) ---\n",
    "            log_run_inputs(cfg)\n",
    "            log_config_snapshot(cfg)\n",
    "\n",
    "            # --- 2) Slice data ---\n",
    "            train_df, test_df = slice_by_time(df_pd, cfg.time_split)\n",
    "            ycol = get_target_col(cfg.target_node)\n",
    "\n",
    "            # Basic guards (kept simple)\n",
    "            if len(cfg.features) == 0:\n",
    "                raise ValueError(\"cfg.features is empty.\")\n",
    "            missing_cols = [c for c in cfg.features + (ycol,) if c not in train_df.columns]\n",
    "            if missing_cols:\n",
    "                raise ValueError(f\"Missing columns in df_pd: {missing_cols}\")\n",
    "\n",
    "            X_train = train_df.loc[:, list(cfg.features)]\n",
    "            y_train = train_df[ycol]\n",
    "            X_test = test_df.loc[:, list(cfg.features)]\n",
    "            y_test = test_df[ycol]\n",
    "\n",
    "            # --- 3) Fit + build coefficients table (with p-values only for OLS) ---\n",
    "            model, cdf = fit_and_get_coef_table(cfg, X_train, y_train)\n",
    "\n",
    "            # Add run context directly into the coefficient table (helps aggregation later)\n",
    "            cdf[\"target_node\"] = cfg.target_node\n",
    "            cdf[\"panel_control\"] = cfg.panel_control\n",
    "            cdf[\"algorithm\"] = cfg.algorithm\n",
    "            cdf[\"feature_block_set_id\"] = cfg.feature_block_set_id\n",
    "            cdf[\"time_split_id\"] = cfg.time_split.time_split_id\n",
    "\n",
    "            # --- 4) Predict (handle statsmodels vs sklearn) ---\n",
    "            if cfg.algorithm == \"OLS\":\n",
    "                pred_train = model.predict(sm.add_constant(X_train, has_constant=\"add\"))\n",
    "                pred_test = model.predict(sm.add_constant(X_test, has_constant=\"add\"))\n",
    "            else:\n",
    "                pred_train = model.predict(X_train)\n",
    "                pred_test = model.predict(X_test)\n",
    "\n",
    "            # --- 5) Log metrics ---\n",
    "            log_metrics(\"train\", y_train, pred_train)\n",
    "            log_metrics(\"test\", y_test, pred_test)\n",
    "\n",
    "            # Optional: log a couple simple summary metrics from coefficient table\n",
    "            # (e.g. number significant; works for OLS only)\n",
    "            if cdf[\"p_value\"].notna().any():\n",
    "                mlflow.log_metric(\"n_significant_05\", float((cdf[\"p_value\"] < 0.05).sum()))\n",
    "                mlflow.log_metric(\"pct_significant_05\", float((cdf[\"p_value\"] < 0.05).mean()))\n",
    "            else:\n",
    "                mlflow.log_metric(\"n_significant_05\", np.nan)\n",
    "                mlflow.log_metric(\"pct_significant_05\", np.nan)\n",
    "\n",
    "            # For ElasticNet, you may care about selection rate (non-zero)\n",
    "            if cfg.algorithm == \"ElasticNet\":\n",
    "                mlflow.log_metric(\"n_nonzero_coef\", float((cdf[\"coef\"].abs() > 1e-12).sum()))\n",
    "                mlflow.log_metric(\"pct_nonzero_coef\", float((cdf[\"coef\"].abs() > 1e-12).mean()))\n",
    "\n",
    "            # --- 6) Log artifacts (system of record for per-feature consolidation) ---\n",
    "            log_dataframe_as_csv(cdf, artifact_path=\"artifacts\", filename=\"coefficients.csv\")\n",
    "\n",
    "        except Exception as e:\n",
    "            mlflow.set_tag(\"run_status\", \"failed\")\n",
    "            mlflow.log_text(str(e), \"error.txt\")\n",
    "            raise\n",
    "        else:\n",
    "            mlflow.set_tag(\"run_status\", \"ok\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Orchestrator (parent run + many child runs)\n",
    "\n",
    "This matches the MLflow tutorial pattern (parent run contains the “study”, child runs contain each trial)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def run_study(\n",
    "#     df_pd: pd.DataFrame,\n",
    "#     experiment_name: str,\n",
    "#     study_name: str,\n",
    "#     common_tags: Dict[str, str],\n",
    "#     configs: Iterator[RunConfig],\n",
    "#     max_runs: int = None,\n",
    "# ) -> str:\n",
    "#     setup_mlflow(experiment_name, common_tags)\n",
    "\n",
    "#     with mlflow.start_run(run_name=study_name) as parent:\n",
    "#         mlflow.set_tag(\"run_type\", \"study\")\n",
    "#         mlflow.log_param(\"study_name\", study_name)\n",
    "\n",
    "#         n = 0\n",
    "#         for cfg in configs:\n",
    "#             if max_runs is not None and n >= max_runs:\n",
    "#                 break\n",
    "#             run_one_experiment(df_pd, cfg)\n",
    "#             n += 1\n",
    "\n",
    "#         mlflow.log_param(\"n_child_runs\", n)\n",
    "#         return parent.info.run_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_study(\n",
    "    df_pd: pd.DataFrame,\n",
    "    experiment_name: str,\n",
    "    study_name: str,\n",
    "    common_tags: Dict[str, str],\n",
    "    configs: Iterator[RunConfig],\n",
    "    max_runs: int = None,\n",
    ") -> str:\n",
    "    # extra safety for notebooks: close anything dangling\n",
    "    while mlflow.active_run() is not None:\n",
    "        mlflow.end_run()\n",
    "\n",
    "    setup_mlflow(experiment_name)\n",
    "\n",
    "    # start parent run FIRST, then set tags\n",
    "    with mlflow.start_run(run_name=study_name) as parent:\n",
    "        mlflow.set_tags(common_tags)          # ✅ now safe\n",
    "        mlflow.set_tag(\"run_type\", \"study\")\n",
    "        mlflow.log_param(\"study_name\", study_name)\n",
    "\n",
    "        n = 0\n",
    "        for cfg in configs:\n",
    "            if max_runs is not None and n >= max_runs:\n",
    "                break\n",
    "            run_one_experiment(df_pd, cfg)     # child run MUST be nested=True\n",
    "            n += 1\n",
    "\n",
    "        mlflow.log_param(\"n_child_runs\", n)\n",
    "        return parent.info.run_id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10) Retrieve results + feature stability summary (simple version)\n",
    "\n",
    "This is the “later I’ll decide which features to keep” part — implemented minimally using MLflow search + the logged coefficient artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_coefficients_for_run(run_id: str) -> pd.DataFrame:\n",
    "    # Download the artifact and read it\n",
    "    local_dir = mlflow.artifacts.download_artifacts(run_id=run_id, artifact_path=\"artifacts/coefficients.csv\")\n",
    "    return pd.read_csv(local_dir)\n",
    "\n",
    "def aggregate_feature_stability(\n",
    "    experiment_name: str,\n",
    "    filter_query: str = \"tags.run_status = 'ok'\",\n",
    ") -> pd.DataFrame:\n",
    "    exp = mlflow.get_experiment_by_name(experiment_name)\n",
    "    runs = mlflow.search_runs(experiment_ids=[exp.experiment_id], filter_string=filter_query)\n",
    "\n",
    "    rows = []\n",
    "    for _, r in runs.iterrows():\n",
    "        run_id = r[\"run_id\"]\n",
    "        try:\n",
    "            cdf = load_coefficients_for_run(run_id)\n",
    "            cdf[\"run_id\"] = run_id\n",
    "            rows.append(cdf[[\"run_id\", \"feature\", \"coef\", \"sign\", \"abs_coef\", \"rank_abscoef\"]])\n",
    "        except Exception:\n",
    "            # If some run didn't log artifacts, skip (or handle stricter)\n",
    "            continue\n",
    "\n",
    "    if not rows:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    allc = pd.concat(rows, ignore_index=True)\n",
    "\n",
    "    # Stability stats you described (simple baseline)\n",
    "    g = allc.groupby(\"feature\")\n",
    "    out = pd.DataFrame({\n",
    "        \"n_runs_appeared\": g[\"run_id\"].nunique(),\n",
    "        \"mean_coef\": g[\"coef\"].mean(),\n",
    "        \"median_coef\": g[\"coef\"].median(),\n",
    "        \"std_coef\": g[\"coef\"].std(ddof=1),\n",
    "        \"mean_abscoef\": g[\"abs_coef\"].mean(),\n",
    "        \"mean_rank\": g[\"rank_abscoef\"].mean(),\n",
    "        \"pct_positive\": g[\"sign\"].apply(lambda s: (s > 0).mean()),\n",
    "        \"pct_negative\": g[\"sign\"].apply(lambda s: (s < 0).mean()),\n",
    "    }).reset_index()\n",
    "\n",
    "    out[\"coef_cv\"] = out[\"std_coef\"] / out[\"mean_coef\"].replace(0, np.nan)\n",
    "    out = out.sort_values([\"n_runs_appeared\", \"mean_abscoef\"], ascending=[False, False]).reset_index(drop=True)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11) Example usage (plug in your df_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>week_start</th>\n",
       "      <th>log_GC</th>\n",
       "      <th>digital_promo_1</th>\n",
       "      <th>digital_promo_2</th>\n",
       "      <th>digital_promo_3</th>\n",
       "      <th>digital_promo_4</th>\n",
       "      <th>digital_promo_5</th>\n",
       "      <th>media_1</th>\n",
       "      <th>media_2</th>\n",
       "      <th>media_3</th>\n",
       "      <th>media_4</th>\n",
       "      <th>media_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>0.304717</td>\n",
       "      <td>-1.376686</td>\n",
       "      <td>0.232170</td>\n",
       "      <td>0.459386</td>\n",
       "      <td>1.403821</td>\n",
       "      <td>0.319400</td>\n",
       "      <td>0.044212</td>\n",
       "      <td>0.529413</td>\n",
       "      <td>-0.955625</td>\n",
       "      <td>0.417472</td>\n",
       "      <td>-1.180001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-08</td>\n",
       "      <td>-1.039984</td>\n",
       "      <td>0.635151</td>\n",
       "      <td>-0.555327</td>\n",
       "      <td>0.701954</td>\n",
       "      <td>-0.442536</td>\n",
       "      <td>-0.869047</td>\n",
       "      <td>-0.202914</td>\n",
       "      <td>1.363429</td>\n",
       "      <td>0.437512</td>\n",
       "      <td>-1.320489</td>\n",
       "      <td>0.804570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-15</td>\n",
       "      <td>0.750451</td>\n",
       "      <td>-0.222223</td>\n",
       "      <td>0.471539</td>\n",
       "      <td>0.138241</td>\n",
       "      <td>1.455046</td>\n",
       "      <td>0.177396</td>\n",
       "      <td>-1.082427</td>\n",
       "      <td>-1.880798</td>\n",
       "      <td>-1.241756</td>\n",
       "      <td>0.854686</td>\n",
       "      <td>-0.675114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-22</td>\n",
       "      <td>0.940565</td>\n",
       "      <td>-1.470806</td>\n",
       "      <td>1.012716</td>\n",
       "      <td>0.760133</td>\n",
       "      <td>0.131486</td>\n",
       "      <td>1.212519</td>\n",
       "      <td>-0.151052</td>\n",
       "      <td>-0.317907</td>\n",
       "      <td>-0.204069</td>\n",
       "      <td>-0.800212</td>\n",
       "      <td>0.403954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-29</td>\n",
       "      <td>-1.951035</td>\n",
       "      <td>-1.015579</td>\n",
       "      <td>0.155429</td>\n",
       "      <td>0.229211</td>\n",
       "      <td>0.258229</td>\n",
       "      <td>-0.323792</td>\n",
       "      <td>-0.746098</td>\n",
       "      <td>-0.867005</td>\n",
       "      <td>0.109648</td>\n",
       "      <td>0.632858</td>\n",
       "      <td>0.565460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>2025-06-01</td>\n",
       "      <td>1.463303</td>\n",
       "      <td>-0.376156</td>\n",
       "      <td>0.276274</td>\n",
       "      <td>1.628937</td>\n",
       "      <td>1.847825</td>\n",
       "      <td>-0.079730</td>\n",
       "      <td>0.555582</td>\n",
       "      <td>0.101926</td>\n",
       "      <td>-0.084851</td>\n",
       "      <td>-2.480709</td>\n",
       "      <td>-0.439988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>2025-06-08</td>\n",
       "      <td>-1.188763</td>\n",
       "      <td>-0.133823</td>\n",
       "      <td>-1.412766</td>\n",
       "      <td>-0.970150</td>\n",
       "      <td>-0.174173</td>\n",
       "      <td>1.797561</td>\n",
       "      <td>-0.622168</td>\n",
       "      <td>-0.762323</td>\n",
       "      <td>-1.600206</td>\n",
       "      <td>-0.996419</td>\n",
       "      <td>-2.955619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>2025-06-15</td>\n",
       "      <td>-0.639752</td>\n",
       "      <td>-1.374896</td>\n",
       "      <td>-2.310103</td>\n",
       "      <td>-0.887696</td>\n",
       "      <td>1.667888</td>\n",
       "      <td>0.894213</td>\n",
       "      <td>0.987405</td>\n",
       "      <td>-0.859206</td>\n",
       "      <td>-0.761974</td>\n",
       "      <td>1.232902</td>\n",
       "      <td>-1.247317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>2025-06-22</td>\n",
       "      <td>-0.926576</td>\n",
       "      <td>-0.238174</td>\n",
       "      <td>0.054354</td>\n",
       "      <td>1.335784</td>\n",
       "      <td>-1.103741</td>\n",
       "      <td>0.011445</td>\n",
       "      <td>1.157508</td>\n",
       "      <td>-0.537663</td>\n",
       "      <td>0.148627</td>\n",
       "      <td>-2.777994</td>\n",
       "      <td>1.120841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>2025-06-29</td>\n",
       "      <td>-0.389810</td>\n",
       "      <td>-0.266387</td>\n",
       "      <td>-0.471776</td>\n",
       "      <td>-0.191344</td>\n",
       "      <td>0.587259</td>\n",
       "      <td>0.248787</td>\n",
       "      <td>1.436302</td>\n",
       "      <td>0.542594</td>\n",
       "      <td>0.366210</td>\n",
       "      <td>-0.347523</td>\n",
       "      <td>-0.664626</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>131 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    week_start    log_GC  digital_promo_1  digital_promo_2  digital_promo_3  \\\n",
       "0   2023-01-01  0.304717        -1.376686         0.232170         0.459386   \n",
       "1   2023-01-08 -1.039984         0.635151        -0.555327         0.701954   \n",
       "2   2023-01-15  0.750451        -0.222223         0.471539         0.138241   \n",
       "3   2023-01-22  0.940565        -1.470806         1.012716         0.760133   \n",
       "4   2023-01-29 -1.951035        -1.015579         0.155429         0.229211   \n",
       "..         ...       ...              ...              ...              ...   \n",
       "126 2025-06-01  1.463303        -0.376156         0.276274         1.628937   \n",
       "127 2025-06-08 -1.188763        -0.133823        -1.412766        -0.970150   \n",
       "128 2025-06-15 -0.639752        -1.374896        -2.310103        -0.887696   \n",
       "129 2025-06-22 -0.926576        -0.238174         0.054354         1.335784   \n",
       "130 2025-06-29 -0.389810        -0.266387        -0.471776        -0.191344   \n",
       "\n",
       "     digital_promo_4  digital_promo_5   media_1   media_2   media_3   media_4  \\\n",
       "0           1.403821         0.319400  0.044212  0.529413 -0.955625  0.417472   \n",
       "1          -0.442536        -0.869047 -0.202914  1.363429  0.437512 -1.320489   \n",
       "2           1.455046         0.177396 -1.082427 -1.880798 -1.241756  0.854686   \n",
       "3           0.131486         1.212519 -0.151052 -0.317907 -0.204069 -0.800212   \n",
       "4           0.258229        -0.323792 -0.746098 -0.867005  0.109648  0.632858   \n",
       "..               ...              ...       ...       ...       ...       ...   \n",
       "126         1.847825        -0.079730  0.555582  0.101926 -0.084851 -2.480709   \n",
       "127        -0.174173         1.797561 -0.622168 -0.762323 -1.600206 -0.996419   \n",
       "128         1.667888         0.894213  0.987405 -0.859206 -0.761974  1.232902   \n",
       "129        -1.103741         0.011445  1.157508 -0.537663  0.148627 -2.777994   \n",
       "130         0.587259         0.248787  1.436302  0.542594  0.366210 -0.347523   \n",
       "\n",
       "      media_5  \n",
       "0   -1.180001  \n",
       "1    0.804570  \n",
       "2   -0.675114  \n",
       "3    0.403954  \n",
       "4    0.565460  \n",
       "..        ...  \n",
       "126 -0.439988  \n",
       "127 -2.955619  \n",
       "128 -1.247317  \n",
       "129  1.120841  \n",
       "130 -0.664626  \n",
       "\n",
       "[131 rows x 12 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import mlflow\n",
    "# while mlflow.active_run() is not None:\n",
    "#     mlflow.end_run()\n",
    "# print(\"Active run now:\", mlflow.active_run())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "local testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_blocks = {\n",
    "    \"promo\": ['digital_promo_1','digital_promo_2','digital_promo_3','digital_promo_4','digital_promo_5'],\n",
    "    \"media\": ['media_1','media_2','media_3','media_4','media_5'],\n",
    "}\n",
    "\n",
    "time_splits = [\n",
    "    TimeSplit(\"ts1\", \"2023-01-01\", \"2024-06-30\", \"2024-07-01\", \"2024-12-31\"),\n",
    "]\n",
    "\n",
    "algorithms = [\n",
    "    {\"name\": \"OLS\"},   # simplest to start (and gives p-values if you used statsmodels in OLS)\n",
    "]\n",
    "\n",
    "feature_sets = generate_feature_sets(feature_blocks)\n",
    "\n",
    "configs_gc = search_space(\n",
    "    target_node=\"GC\",\n",
    "    panel_controls=[\"FE\"],     # keep one for smoke test\n",
    "    algorithms=algorithms,\n",
    "    time_splits=time_splits,\n",
    "    feature_sets={\"block__promo\": feature_sets[\"block__promo\"]},  # one feature set only\n",
    "    seed=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active run before: None\n",
      "           feature  n_runs_appeared  mean_coef  median_coef  std_coef  \\\n",
      "0  digital_promo_1                2  -0.184221    -0.184221       0.0   \n",
      "1  digital_promo_5                2  -0.107128    -0.107128       0.0   \n",
      "2  digital_promo_4                2  -0.052290    -0.052290       0.0   \n",
      "3  digital_promo_3                2  -0.023930    -0.023930       0.0   \n",
      "4  digital_promo_2                2   0.011568     0.011568       0.0   \n",
      "\n",
      "   mean_abscoef  mean_rank  pct_positive  pct_negative  coef_cv  \n",
      "0      0.184221        1.0           0.0           1.0     -0.0  \n",
      "1      0.107128        2.0           0.0           1.0     -0.0  \n",
      "2      0.052290        3.0           0.0           1.0     -0.0  \n",
      "3      0.023930        4.0           0.0           1.0     -0.0  \n",
      "4      0.011568        5.0           1.0           0.0      0.0  \n"
     ]
    }
   ],
   "source": [
    "print(\"Active run before:\", mlflow.active_run())\n",
    "\n",
    "parent_run_id = run_study(\n",
    "    df_pd=df,\n",
    "    experiment_name=\"RGA_Regression_Local\",\n",
    "    study_name=\"GC_smoketest_v001\",\n",
    "    common_tags={\n",
    "        \"project\": \"RevenueGrowthAnalytics\",\n",
    "        \"layer\": \"2\",\n",
    "        \"framework\": \"regression_shell\",\n",
    "        \"env\": \"local\",\n",
    "    },\n",
    "    configs=configs_gc,\n",
    "    max_runs=2,   # <-- smallest smoke test\n",
    ")\n",
    "\n",
    "stability = aggregate_feature_stability(\n",
    "    experiment_name=\"RGA_Regression_Local\",\n",
    "    filter_query=\"tags.run_status = 'ok' and params.target_node = 'GC'\"\n",
    ")\n",
    "\n",
    "print(stability.head(30))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate_feature_stability() slice_by_time(), fit_and_get_coef_table(), and generate_feature_sets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "complex version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example component inputs (you will replace these)\n",
    "# feature_blocks = {\n",
    "#     \"promo\": [\"promo_depth\", \"lto_flag\", \"discount_idx\", \"bundle_idx\", \"coupon_rate\"],\n",
    "#     \"media\": [\"tv_grps\", \"digital_imps\", \"search_spend\", \"social_spend\", \"ooh_spend\"],\n",
    "# }\n",
    "\n",
    "feature_blocks = {\n",
    "    \"promo\": ['digital_promo_1', 'digital_promo_2', 'digital_promo_3',\n",
    "       'digital_promo_4', 'digital_promo_5'],\n",
    "    \"media\": ['media_1', 'media_2', 'media_3', 'media_4',\n",
    "       'media_5'],\n",
    "}\n",
    "\n",
    "time_splits = [\n",
    "    TimeSplit(\"ts1\", \"2023-01-01\", \"2024-06-30\", \"2024-07-01\", \"2024-12-31\"),\n",
    "    TimeSplit(\"ts2\", \"2023-07-01\", \"2024-12-31\", \"2025-01-01\", \"2025-06-30\"),\n",
    "]\n",
    "\n",
    "algorithms = [\n",
    "    {\"name\": \"OLS\"},\n",
    "    {\"name\": \"Ridge\", \"alpha\": 1.0},\n",
    "    {\"name\": \"ElasticNet\", \"alpha\": 0.1, \"l1_ratio\": 0.5},\n",
    "]\n",
    "\n",
    "feature_sets = generate_feature_sets(feature_blocks)\n",
    "\n",
    "configs_gc = search_space(\n",
    "    target_node=\"GC\",\n",
    "    panel_controls=[\"FE\", \"Mundlak\"],      # Bayesian later\n",
    "    algorithms=algorithms,\n",
    "    time_splits=time_splits,\n",
    "    feature_sets=feature_sets,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "parent_run_id = run_study(\n",
    "    df_pd=df,\n",
    "    # experiment_name=\"/Users/your.name@company.com/RGA_Regression\",\n",
    "    experiment_name=\"RGA_Regression_Local\",\n",
    "    study_name=\"GC_study_v001\",\n",
    "    common_tags={\n",
    "        \"project\": \"RevenueGrowthAnalytics\",\n",
    "        \"layer\": \"2\",\n",
    "        \"framework\": \"regression_shell\",\n",
    "    },\n",
    "    configs=configs_gc,\n",
    "    max_runs=50,   # remove later\n",
    ")\n",
    "\n",
    "# Aggregate stability\n",
    "stability = aggregate_feature_stability(\n",
    "    experiment_name=\"/Users/your.name@company.com/RGA_Regression\",\n",
    "    filter_query=\"tags.run_status = 'ok' and params.target_node = 'GC'\"\n",
    ")\n",
    "\n",
    "display(stability.head(30))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import mlflow\n",
    "# from mlflow.tracking import MlflowClient\n",
    "\n",
    "# print(\"Tracking URI:\", mlflow.get_tracking_uri())\n",
    "# print(\"Active run:\", mlflow.active_run())\n",
    "\n",
    "# client = MlflowClient()\n",
    "# exps = client.search_experiments()\n",
    "# print(\"Experiments found:\", [e.name for e in exps][:10])\n",
    "\n",
    "# print(TRACK_DIR)\n",
    "\n",
    "# import os, mlflow\n",
    "# TRACK_DIR = os.path.abspath(\"./mlruns_rga_test\")\n",
    "# mlflow.set_tracking_uri(\"file:///\" + TRACK_DIR.replace(\"\\\\\", \"/\"))\n",
    "# print(\"Tracking URI set to:\", mlflow.get_tracking_uri())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mlflow.tracking import MlflowClient\n",
    "# client = MlflowClient()\n",
    "\n",
    "# exp = client.get_experiment_by_name(\"RGA_Regression_Local\")\n",
    "# print(\"Experiment:\", exp)\n",
    "\n",
    "# runs = client.search_runs([exp.experiment_id], max_results=5)\n",
    "# print(\"Found runs:\", len(runs))\n",
    "# print([r.data.tags.get(\"mlflow.runName\") for r in runs])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(mlflow.get_tracking_uri())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "client = MlflowClient()\n",
    "\n",
    "run = client.get_run(\"15a6649b2b244ec4b624b0d7bfc0afc2\")\n",
    "print(run.data.metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mX_train\u001b[49m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      2\u001b[0m X_test\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "X_train.shape[0] == 0\n",
    "X_test.shape[0] == 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Any\n",
    "import mlflow\n",
    "import statsmodels.api as sm\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class FinalSpec:\n",
    "    name: str                  # e.g., \"GC_final_v001\"\n",
    "    target_node: str           # \"GC\" / \"AC\"\n",
    "    panel_control: str         # \"FE\" / \"Mundlak\" / \"Bayesian\"\n",
    "    algorithm: str             # \"OLS\" / \"Ridge\" / \"ElasticNet\"\n",
    "    alpha: float = 0.0\n",
    "    l1_ratio: float = 0.0\n",
    "    features: List[str] = None\n",
    "    train_start: str = None\n",
    "    train_end: str = None\n",
    "\n",
    "def train_final_and_log_model(df_pd, spec: FinalSpec, experiment_name: str, tags: Dict[str,str]):\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "\n",
    "    run_name = spec.name\n",
    "    with mlflow.start_run(run_name=run_name):\n",
    "        # Tag this as a promoted/final run\n",
    "        mlflow.set_tags({**tags, \"run_stage\": \"final\", \"is_champion\": \"true\"})\n",
    "\n",
    "        # Params (full snapshot)\n",
    "        mlflow.log_params({\n",
    "            \"target_node\": spec.target_node,\n",
    "            \"panel_control\": spec.panel_control,\n",
    "            \"algorithm\": spec.algorithm,\n",
    "            \"alpha\": spec.alpha,\n",
    "            \"l1_ratio\": spec.l1_ratio,\n",
    "            \"n_features\": len(spec.features),\n",
    "            \"train_start\": spec.train_start,\n",
    "            \"train_end\": spec.train_end,\n",
    "        })\n",
    "\n",
    "        # Train slice\n",
    "        df = df_pd.copy()\n",
    "        df[\"week_start\"] = pd.to_datetime(df[\"week_start\"])\n",
    "        train_df = df[(df[\"week_start\"] >= spec.train_start) & (df[\"week_start\"] <= spec.train_end)]\n",
    "\n",
    "        ycol = \"log_GC\" if spec.target_node == \"GC\" else \"log_AC\"\n",
    "        X_train = train_df[spec.features]\n",
    "        y_train = train_df[ycol]\n",
    "\n",
    "        # Fit + coeff artifact (reuse your function)\n",
    "        cfg = RunConfig(\n",
    "            target_node=spec.target_node,\n",
    "            panel_control=spec.panel_control,\n",
    "            algorithm=spec.algorithm,\n",
    "            alpha=spec.alpha,\n",
    "            l1_ratio=spec.l1_ratio,\n",
    "            feature_block_set_id=\"FINAL\",\n",
    "            features=tuple(spec.features),\n",
    "            time_split=TimeSplit(\"FINAL\", spec.train_start, spec.train_end, spec.train_start, spec.train_end),\n",
    "            seed=42,\n",
    "        )\n",
    "\n",
    "        model, cdf = fit_and_get_coef_table(cfg, X_train, y_train)\n",
    "        log_dataframe_as_csv(cdf, artifact_path=\"artifacts\", filename=\"coefficients.csv\")\n",
    "\n",
    "        # Log model artifact (ONLY for final)\n",
    "        if spec.algorithm == \"OLS\":\n",
    "            # statsmodels model\n",
    "            mlflow.statsmodels.log_model(model, artifact_path=\"model\")\n",
    "        else:\n",
    "            # sklearn model\n",
    "            import mlflow.sklearn\n",
    "            mlflow.sklearn.log_model(model, artifact_path=\"model\")\n",
    "\n",
    "        # Optional: store the final feature list\n",
    "        mlflow.log_text(\"\\n\".join(spec.features), \"final_features.txt\")\n",
    "\n",
    "        return mlflow.active_run().info.run_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_gc = FinalSpec(\n",
    "    name=\"GC_final_v001\",\n",
    "    target_node=\"GC\",\n",
    "    panel_control=\"Mundlak\",\n",
    "    algorithm=\"Ridge\",\n",
    "    alpha=1.0,\n",
    "    features=[...],                 # your chosen stable features\n",
    "    train_start=\"2023-01-01\",\n",
    "    train_end=\"2025-06-30\",\n",
    ")\n",
    "\n",
    "run_id = train_final_and_log_model(\n",
    "    df_pd=df,\n",
    "    spec=final_gc,\n",
    "    experiment_name=\"RGA_Regression_Local\",\n",
    "    tags={\"project\":\"RevenueGrowthAnalytics\", \"layer\":\"2\"}\n",
    ")\n",
    "print(\"Final model run_id:\", run_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c1195de73a404f6a9e5befacc0862eb4 GC__FE__OLS__block__promo__ts1\n"
     ]
    }
   ],
   "source": [
    "runs = client.search_runs(\n",
    "    experiment_ids=[exp.experiment_id],\n",
    "    filter_string=\"tags.run_status = 'ok'\",\n",
    "    order_by=[\"attributes.start_time DESC\"],\n",
    "    max_results=5\n",
    ")\n",
    "\n",
    "for r in runs:\n",
    "    print(r.info.run_id, r.data.tags.get(\"mlflow.runName\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "run = client.get_run(\"41894288e1974559b68c3337fb586335\")\n",
    "print(run.data.metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8510b0a2bd9b431291963245548f5017 GC__FE__OLS__block__promo__ts1 0.7691974572947565\n"
     ]
    }
   ],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "client = MlflowClient()\n",
    "\n",
    "exp = client.get_experiment_by_name(\"RGA_Regression_Local\")\n",
    "\n",
    "runs = client.search_runs(\n",
    "    experiment_ids=[exp.experiment_id],\n",
    "    filter_string=\"tags.run_status = 'ok' and tags.run_type != 'study'\",\n",
    "    order_by=[\"attributes.start_time DESC\"],\n",
    "    max_results=20,\n",
    ")\n",
    "\n",
    "for r in runs:\n",
    "    print(r.info.run_id, r.data.tags.get(\"mlflow.runName\"), r.data.metrics.get(\"test_rmse\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
